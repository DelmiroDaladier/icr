---
categories: computer vision and pattern recognition
description: Recent years have witnessed considerable achievements in editing images
  withtext instructions. When applying these editors to dynamic scene editing, thenew-style
  scene tends to be temporally inconsistent due to the frame-by-framenature of these
  2D editors. To tackle this issue, we propose Control4D, a novelapproach for high-fidelity
  and temporally consistent 4D portrait editing.Control4D is built upon an efficient
  4D representation with a 2Ddiffusion-based editor. Instead of using direct supervisions
  from the editor,our method learns a 4D GAN from it and avoids the inconsistent supervisionsignals.
  Specifically, we employ a discriminator to learn the generationdistribution based
  on the edited images and then update the generator with thediscrimination signals.
  For more stable training, multi-level information isextracted from the edited images
  and used to facilitate the learning of thegenerator. Experimental results show that
  Control4D surpasses previousapproaches and achieves more photo-realistic and consistent
  4D editingperformances. The link to our project website isthis https URL
execute:
  echo: false
format:
  html:
    df-print: paged
    toc: true
image: https://upload.wikimedia.org/wikipedia/commons/5/59/Empty.png
params:
  author_1:
    name: Shao, Ruizhi
  author_2:
    name: Sun, Jingxiang
  author_3:
    name: Peng, Cheng
  author_4:
    name: Zheng, Zerong
  author_5:
    name: Zhou, Boyao
  author_6:
    name: Zhang, Hongwen
  author_7:
    name: Liu, Yebin
  overview: Recent years have witnessed considerable achievements in editing images
    withtext instructions. When applying these editors to dynamic scene editing, thenew-style
    scene tends to be temporally inconsistent due to the frame-by-framenature of these
    2D editors. To tackle this issue, we propose Control4D, a novelapproach for high-fidelity
    and temporally consistent 4D portrait editing.Control4D is built upon an efficient
    4D representation with a 2Ddiffusion-based editor. Instead of using direct supervisions
    from the editor,our method learns a 4D GAN from it and avoids the inconsistent
    supervisionsignals. Specifically, we employ a discriminator to learn the generationdistribution
    based on the edited images and then update the generator with thediscrimination
    signals. For more stable training, multi-level information isextracted from the
    edited images and used to facilitate the learning of thegenerator. Experimental
    results show that Control4D surpasses previousapproaches and achieves more photo-realistic
    and consistent 4D editingperformances. The link to our project website isthis
    https URL
  pdf_url: http://arxiv.org/pdf/2305.20082
title: 'Control4D: Dynamic Portrait Editing by Learning 4D GAN from 2D Diffusion-based
  Editor'

---
```{ojs} 

 names = ["Ruizhi Shao","Jingxiang Sun","Cheng Peng","Zerong Zheng","Boyao Zhou","Hongwen Zhang","Yebin Liu"] 

``` 

## Tldr 
Recent years have witnessed considerable achievements in editing images withtext instructions. When applying these editors to dynamic scene editing, thenew-style scene tends to be temporally inconsistent due to the frame-by-framenature of these 2D editors. To tackle this issue, we propose Control4D, a novelapproach for high-fidelity and temporally consistent 4D portrait editing.Control4D is built upon an efficient 4D representation with a 2Ddiffusion-based editor. Instead of using direct supervisions from the editor,our method learns a 4D GAN from it and avoids the inconsistent supervisionsignals. Specifically, we employ a discriminator to learn the generationdistribution based on the edited images and then update the generator with thediscrimination signals. For more stable training, multi-level information isextracted from the edited images and used to facilitate the learning of thegenerator. Experimental results show that Control4D surpasses previousapproaches and achieves more photo-realistic and consistent 4D editingperformances. The link to our project website isthis https URL

## Paper-authors

```{ojs} 

 html`<ul>${names.map(name => html`<li><a href="../../posts_by_author.html?name=${name}" >${name}</a></li>`)}</ul>` 

``` 

```{ojs} 

 htl = require("htl@0.2") 

``` 

```{ojs} 

 html = htl.html 

``` 

## More Resources
[![](https://img.shields.io/badge/PDF-green?style=flat)]({{< meta params.pdf_url >}})
