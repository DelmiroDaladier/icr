---
categories: artificial intelligence
description: Recent studies have shown that Large Language Models (LLMs) can be utilizedfor
  solving complex sequential decision-making tasks by providing high-levelinstructions.
  However, LLM-based agents face limitations in real-time dynamicenvironments due
  to their lack of specialization in solving specific targetproblems. Moreover, the
  deployment of such LLM-based agents is both costly andtime-consuming in practical
  scenarios. In this paper, we introduce a novelframework that addresses these challenges
  by training a smaller scalespecialized student agent using instructions from an
  LLM-based teacher agent.By leveraging guided actions provided by the teachers, the
  prior knowledge ofthe LLM is distilled into the local student model. Consequently,
  the studentagent can be trained with significantly less data. Furthermore, subsequenttraining
  with environment feedback empowers the student agents to surpass thecapabilities
  of their teachers. We conducted experiments on three challengingMiniGrid environments
  to evaluate the effectiveness of our framework. Theresults demonstrate that our
  approach enhances sample efficiency and achievessuperior performance compared to
  baseline methods.
execute:
  echo: false
format:
  html:
    df-print: paged
    toc: true
image: https://upload.wikimedia.org/wikipedia/commons/5/59/Empty.png
params:
  author_1:
    link: https://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1
    name: Zhou, Zihao
  author_2:
    link: https://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1
    name: Hu, Bin
  author_3:
    link: https://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1
    name: Zhang, Pu
  author_4:
    link: https://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1
    name: Zhao, Chenyang
  author_5:
    link: https://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1
    name: Liu, Bin
  overview: Recent studies have shown that Large Language Models (LLMs) can be utilizedfor
    solving complex sequential decision-making tasks by providing high-levelinstructions.
    However, LLM-based agents face limitations in real-time dynamicenvironments due
    to their lack of specialization in solving specific targetproblems. Moreover,
    the deployment of such LLM-based agents is both costly andtime-consuming in practical
    scenarios. In this paper, we introduce a novelframework that addresses these challenges
    by training a smaller scalespecialized student agent using instructions from an
    LLM-based teacher agent.By leveraging guided actions provided by the teachers,
    the prior knowledge ofthe LLM is distilled into the local student model. Consequently,
    the studentagent can be trained with significantly less data. Furthermore, subsequenttraining
    with environment feedback empowers the student agents to surpass thecapabilities
    of their teachers. We conducted experiments on three challengingMiniGrid environments
    to evaluate the effectiveness of our framework. Theresults demonstrate that our
    approach enhances sample efficiency and achievessuperior performance compared
    to baseline methods.
  pdf_url: http://arxiv.org/pdf/2311.13373
  research_area: artificial intelligence
title: Large Language Model is a Good Policy Teacher for Training Reinforcement Learning
  Agents

---
```{ojs} 

 names = ["Zihao Zhou","Bin Hu","Pu Zhang","Chenyang Zhao","Bin Liu"] 

``` 

## Tldr 
Recent studies have shown that Large Language Models (LLMs) can be utilizedfor solving complex sequential decision-making tasks by providing high-levelinstructions. However, LLM-based agents face limitations in real-time dynamicenvironments due to their lack of specialization in solving specific targetproblems. Moreover, the deployment of such LLM-based agents is both costly andtime-consuming in practical scenarios. In this paper, we introduce a novelframework that addresses these challenges by training a smaller scalespecialized student agent using instructions from an LLM-based teacher agent.By leveraging guided actions provided by the teachers, the prior knowledge ofthe LLM is distilled into the local student model. Consequently, the studentagent can be trained with significantly less data. Furthermore, subsequenttraining with environment feedback empowers the student agents to surpass thecapabilities of their teachers. We conducted experiments on three challengingMiniGrid environments to evaluate the effectiveness of our framework. Theresults demonstrate that our approach enhances sample efficiency and achievessuperior performance compared to baseline methods.

## Paper-authors

```{ojs} 

 html`<ul>${names.map(name => html`<li><a href="../../posts_by_author.html?name=${name}" >${name}</a></li>`)}</ul>` 

``` 

```{ojs} 

 htl = require("htl@0.2") 

``` 

```{ojs} 

 html = htl.html 

``` 

## More Resources
[![](https://img.shields.io/badge/PDF-green?style=flat)]({{< meta params.pdf_url >}})
