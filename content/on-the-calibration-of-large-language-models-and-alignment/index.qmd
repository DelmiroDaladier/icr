---
categories: computation and language
description: 'As large language models attract increasing attention and find widespreadapplication,
  concurrent challenges of reliability also arise at the same time.Confidence calibration,
  an effective analysis method for gauging thereliability of deep models, serves as
  a crucial tool for assessing andimproving their reliability. However, such investigation
  has been comparativelyunderexplored. In this work, we conduct a systematic examination
  of thecalibration of aligned language models throughout the entire constructionprocess,
  including pretraining and alignment training. At each stage, weinvestigate how different
  training settings, such as parameter scales andtraining data, affect model calibration.
  To thoroughly assess modelcalibration, we evaluate models on three most concerned
  aspects: generation,factuality and understanding. Our work sheds light on whether
  popular LLMs arewell-calibrated and how the training process influences model calibration.'
execute:
  echo: false
format:
  html:
    df-print: paged
    toc: true
image: https://upload.wikimedia.org/wikipedia/commons/5/59/Empty.png
params:
  author_1:
    link: https://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1
    name: Zhu, Chiwei
  author_2:
    link: https://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1
    name: Xu, Benfeng
  author_3:
    link: https://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1
    name: Wang, Quan
  author_4:
    link: https://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1
    name: Zhang, Yongdong
  author_5:
    link: https://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1
    name: Mao, Zhendong
  overview: 'As large language models attract increasing attention and find widespreadapplication,
    concurrent challenges of reliability also arise at the same time.Confidence calibration,
    an effective analysis method for gauging thereliability of deep models, serves
    as a crucial tool for assessing andimproving their reliability. However, such
    investigation has been comparativelyunderexplored. In this work, we conduct a
    systematic examination of thecalibration of aligned language models throughout
    the entire constructionprocess, including pretraining and alignment training.
    At each stage, weinvestigate how different training settings, such as parameter
    scales andtraining data, affect model calibration. To thoroughly assess modelcalibration,
    we evaluate models on three most concerned aspects: generation,factuality and
    understanding. Our work sheds light on whether popular LLMs arewell-calibrated
    and how the training process influences model calibration.'
  pdf_url: http://arxiv.org/pdf/2311.13240
  research_area: computation and language
title: On the Calibration of Large Language Models and Alignment

---
```{ojs} 

 names = ["Chiwei Zhu","Benfeng Xu","Quan Wang","Yongdong Zhang","Zhendong Mao"] 

``` 

## Tldr 
As large language models attract increasing attention and find widespreadapplication, concurrent challenges of reliability also arise at the same time.Confidence calibration, an effective analysis method for gauging thereliability of deep models, serves as a crucial tool for assessing andimproving their reliability. However, such investigation has been comparativelyunderexplored. In this work, we conduct a systematic examination of thecalibration of aligned language models throughout the entire constructionprocess, including pretraining and alignment training. At each stage, weinvestigate how different training settings, such as parameter scales andtraining data, affect model calibration. To thoroughly assess modelcalibration, we evaluate models on three most concerned aspects: generation,factuality and understanding. Our work sheds light on whether popular LLMs arewell-calibrated and how the training process influences model calibration.

## Paper-authors

```{ojs} 

 html`<ul>${names.map(name => html`<li><a href="../../posts_by_author.html?name=${name}" >${name}</a></li>`)}</ul>` 

``` 

```{ojs} 

 htl = require("htl@0.2") 

``` 

```{ojs} 

 html = htl.html 

``` 

## More Resources
[![](https://img.shields.io/badge/PDF-green?style=flat)]({{< meta params.pdf_url >}})
